\section{Implementation}
\label{sec:implementation}

We implement a prototype of \sysname with $\sim$3100 LOC in Python, using 
Kubernetes~\cite{k8s} for instance management, Minio~\cite{MinIO} for function 
data management, and SciPy~\cite{scipy} for workload prediction.

\parabf{Instance manager.} We use containers as the serverless function instance 
based on the Kubernetes container orchestration. Each function instance is exposed 
via a unique Pod IP address, which the scheduler maintains in a pod-IP mapping 
table. Container resource limits and instance placement are enforced through 
Kubernetes Pod specifications and node-affinity rules, respectively. In the 
prototype, the scheduler must manage a large number of instances and frequently 
interact with each one to perform lifecycle operations\textemdash including startup, access, 
scaling, termination, and health monitoring. To reduce control-plane overhead, 
our implementation leverages the Python Kubernetes client library in a multi-process 
and multi-coroutine architecture. Since some benchmarks require reading from and 
writing to external data during execution, we additionally deploy a MinIO service 
within the cluster to provide a unified data management layer for the function 
system.

\parabf{Scheduler.} The scheduler in the prototype consists of four modules.
i) The routing plan generator runs as a periodic cluster-level service. It executes the complementary swarming routing algorithm to compute the optimized request routing plan, with an execution period of one minute, matching the instance scaling interval commonly used in industrial and open-source practice~\cite{aws_scaling_window, knative_scaling_window}.
ii) The request router operates as a separate cluster-level process. It assigns each incoming request to a worker node according to the latest routing plan.
iii) The worker scheduler runs locally on each worker node. It maintains per-function request queues, applies the monotonic scale-up scheduling policy to determine execution order, and triggers in-place pod scaling when required.
iv) The system monitor collects real-time resource usage and per-function metrics (\eg cold-start time, execution duration, resource demand distribution). For load prediction, it currently employs a basic FFT-based method implemented with the Python SciPy~library~\cite{scipy}.
