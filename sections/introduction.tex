\section{Introduction}
\label{sec:introduction}

Serverless computing is an emerging cloud paradigm that abstracts away server management, allowing developers to focus solely on application logic~\cite{CACM19:Rise, TR19:Berkeley, CACM21:Serverless}. In this model, developers deploy programs as cloud functions, and the platform automatically manages the underlying infrastructure, including resource provisioning and auto-scaling. The paradigm's simplicity and efficiency have led to its widespread adoption in domains ranging from web applications and data processing pipelines~\cite{Doc:AzureWebApp, NSDI19:Shuffling, OSDI18:Pocket} to machine learning workloads~\cite{SC20:Batch, OSDI21:Dorylus}. For cloud providers, however, delivering on the promise of serverless requires extreme resource efficiency across a multi-tenant fleet of servers.

The prevailing approaches to efficient resource management typically pursue simple objectives like balancing load~\cite{SoCC22:Hermod, Doc:Knative, Doc:OpenFaaS} or maximizing the reuse of warm instances~\cite{ASPLOS21:FaasCache, ASPLOS24:RainbowCake, ASPLOS22:IceBreaker, ATC20:SitW, SoCC22:Hermod, Doc:OpenWhisk}. However, these approaches are resource-inefficient because they ignore the diverse resource footprints of different functions. A scheduler might place several memory-intensive functions on the same node, rapidly exhausting its memory while leaving CPU cores idle. This creates stranded resources, leading to poor cluster-wide utilization because the node cannot accept new functions that require memory, even though it has ample CPU capacity.

Furthermore, existing resource allocation strategies operate at the function level, where each function instance is allocated a static resource capacity~\cite{Doc:AWS_Lambda_Mem, Doc:Azure_Functions_Hosting, Doc:GCP_CloudRun_Mem, ASPLOS21:FaasCache} \todo{add a few more papers with static allocation}. This strategy is predicated on the assumption that a function exhibits uniform resource demands across all its invocations. However, this one-size-fits-all approach often leads to significant resource inefficiency, as it fails to adapt to dynamic, input-dependent workload variations.

We confirm these inefficiencies by conducting a comprehensive analysis over a wide range of real-world serverless applications (\S\ref{sec:demand-analysis}). Our analysis shows that i) the CPU-to-memory ratios of different functions differ by up to \todo{}\% which leads to sigficant resource stranding with existing placement strategies; ii) and the resource usage varies by up to \todo{}\% across a set of typical inputs which forces over-provisioning of resources under static resource allocation. 

To overcome these inefficiencies, we present \sysname, a serverless computing system that handles heterogeneity of functions and requests with a two-pronged solution. At the inter-function level, we introduce complementary swarming, a function placement strategy that mitigates resource stranding by co-locating functions with opposing resource requirements while preserving locality. At the intra-function level, we design a monotonic scale-up request scheduling policy that reorders the request queue for a function to enforce monotonic resource adjustment which avoids the high overhead of instance restarts. Together, these techniques allow \sysname to significantly improve cluster utilization.

The complementary swarming placement strategy operates by first classifying functions based on their resource profiles (i.e., CPU usage and memory usage). It then employs a packing algorithm that treats CPU and memory as distinct dimensions, pairing functions with opposing resource needs onto the same physical node. This co-location of complementary workloads ensures that a node's full capacity is utilized, preventing one resource dimension from becoming a bottleneck while another sits idle and thereby maximizing server density.

The ability to manage resources at the request level is enabled by recent techniques that permit the dynamic, in-place adjustment of a container's resource capacity \todo{citations}. The monotonic scale-up scheduling algorithm is designed to leverage this capability while mitigating the high overhead of scale-down operations. The algorithm organizes incoming requests into multiple queues, each sorted by monotonically increasing resource demands. A warm instance processes requests sequentially from a single queue, ensuring its resource capacity is almost always scaled up. Costly scale-down operations are only performed infrequently, thereby amortizing their high cost across many requests.

The key contributions of this paper are as follows:
\begin{itemize}
    \item We conduct a comprehensive characterization of real-world serverless workloads, identifying and quantifying the resource inefficiency caused by function and request heterogeneity.
    \item We design \sysname, a serverless computing system that co-locates functions with complementary resource requirements and dynamically adjust resources at the request level with complementary swarming for placement and monotonic scale-up for scheduling.
    \item We implement and evaluate \sysname on real-world workloads and demonstrate that it improves resource utilization by up to \todo{}\% and increases cluster throughput by up to \todo{}\% compared to state-of-the-art serverless computing systems.
\end{itemize}

\todo{maybe need a table to compare \sysname with existing solutions}

%Resource management in serverless computing has been an extensively studied problem~\cite{FaaSCache_ASPLOS21}, with numerous solutions proposed in the literature\todo{citation}.
%Most existing approaches operate at the function level; that is, resources are allocated to function instances, which further select requests to process.
%A key assumption underlying these approaches is that a serverless function exhibits consistent resource demands across all invocations.
%
%However, recent analyses of real-world serverless workloads have revealed significant skew in resource consumption across different requests for the same function\todo{citation}.
%Our analysis (\S\ref{sec:demand-analysis}) also confirms that the resource usage of a serverless function can vary by up to XXX times\todo{variation} across different requests.
%This high variability leads to significant inefficiencies for conventional, function-level policies.
%To guarantee reliable performance, these policies must provision resources for a function's peak (i.e., worst-case) demand, resulting in substantial resource wastage for the vast majority of less-demanding requests. 
%Additionally, we find that this input-dependent resource usage is not only skewed but also highly predictable, achieving an accuracy of XXX\%\todo{prediction accuracy}.
%
%Concurrently, techniques that allow for dynamic adjustment of a container's resource capacity have been proposed\todo{citation(k8s, escra, etc.)}.
%These techniques make it possible to alter the resource allocation of a running container in-place, thereby avoiding the costly overhead of resource reallocation.
%
%Capitalizing on these developments, we propose a \textit{request-level} resource allocation policy that provisions the exact amount of resources for each request.
%The key idea is to predict the resource demand of each incoming request and dynamically adjust the target container's resource capacity accordingly.
%Such a fine-grained strategy ensures that requests are processed using only the necessary resources, which can significantly reduce cluster-wide resource wastage.
%
%However, realizing an effective request-level resource management system introduces two challenges.
%First, to achieve high resource utilization through dynamic resource reallocation, the system must rely on oversubscription,
%where the sum of maximum possible resources required for colocated containers exceeds the physical capacity of the server.
%Given the high variability in per-request resource demands, a high oversubscription ratio leads to resource contention and frequent container evictions.
%This forces the system to adopt a low oversubscription ratio, negating much of the potential efficiency gains from request-level resource allocation.
%
%Second, dynamic resource adjustment mechanisms introduce non-negligible overhead.
%Specifically, while increasing a container's resource capacity is a relatively fast operation, decreasing it is often much slower.
%For example, reducing the memory capacity of a container requires reclaiming memory pages, which incurs substantial latency.
%As resource adjustment occurs on the critical path of request execution, this latency directly increases the end-to-end request handling time.
%
%To address these challenges, we propose \sysname, a serverless resource manager that allocates resources at the request level.
%To mitigate the risk of eviction from oversubscription, \sysname adopts a XXX\todo{placement algorithm name} placement strategy.
%This strategy classifies requests into distinct tiers based on their predicted resource demands and specializes containers to handle requests from specific tiers.
%Moreover, this strategy incorporates a XXX\todo{Other feature of placement algorithm. E.g., coloring.} technique to maximize server utilization by colocating containers with complementary resource requirements.
%
%
%\sysname further tackles the overhead of resource adjustment with a XXX\todo{scheduling algorithm name} request scheduling algorithm.
%This algorithm organizes incoming requests into monotonic queues, where requests are sorted by increasing resource demand.
%By processing the requests in a queue sequentially, a container's resource capacity only needs to be incrementally increased.
%A costly resource-decreasing operation is only required when the system finishes one queue and switches to another with a lower starting resource requirement.
%This design reduces the number of resource-decreasing operations, thereby significantly mitigating its impact on overall latency.
%
%Experiments show that \todo{summary of experiments results.}
%
%\todo{summary of contributions.}